{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1个ResNet块包括两个卷积层和一个残差连接，其中输入和输出的尺寸相同。\n",
    "\n",
    "class ResNetBlock(nn.Module):\n",
    "    expansion = 4\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, stride):\n",
    "        super(ResNetBlock, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv3 = nn.Conv2d(out_channels, out_channels * self.expansion, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels * self.expansion:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels * self.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels * self.expansion)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = nn.ReLU()(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = nn.ReLU()(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        out += self.shortcut(identity)\n",
    "        out = nn.ReLU()(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=2):\n",
    "        super(ResNet50, self).__init__()\n",
    "        \n",
    "        self.in_channels = 64\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.layer1 = self._make_layer(block, 64, layers[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "        \n",
    "    def _make_layer(self, block, out_channels, blocks, stride):\n",
    "        layers = []\n",
    "        \n",
    "        layers.append(block(self.in_channels, out_channels, stride))\n",
    "        self.in_channels = out_channels * block.expansion\n",
    "        \n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.in_channels, out_channels, 1))\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = nn.ReLU()(out)\n",
    "        out = self.maxpool(out)\n",
    "\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        \n",
    "        out = self.avgpool(out)\n",
    "        out = torch.flatten(out, 1)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class index 0: C\n",
      "Class index 1: N\n"
     ]
    }
   ],
   "source": [
    "# 定义超参数\n",
    "num_epochs = 10\n",
    "batch_size = 16\n",
    "learning_rate = 0.001\n",
    "\n",
    "# 加载数据集\n",
    "train_dir='/home/ubuntu/DeepLearning/Data/Alexnet_DataSet/train'\n",
    "test_dir='/home/ubuntu/DeepLearning/Data/Alexnet_DataSet/val'\n",
    "\n",
    "\n",
    "transform = transforms.Compose([transforms.Grayscale(num_output_channels=1), transforms.ToTensor()])\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "test_dataset = datasets.ImageFolder(root=test_dir, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# 初始化模型\n",
    "model = ResNet50(ResNetBlock, [3, 4, 6, 3]).to('cuda')\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 用 train_dataset.classes \n",
    "# 属性来获取数据集中的所有类别，并将其与相应的索引映射起来\n",
    "for i, class_name in enumerate(train_dataset.classes):    \n",
    "    print(f\"Class index {i}: {class_name}\")\n",
    "    # Class index 0:C\n",
    "    # Class index 1:N\n",
    "\n",
    "\n",
    "# 创建一个SummaryWriter对象，指定要保存Tensorboard日志的目录：\n",
    "writer = SummaryWriter('logs')\n",
    "# 定义训练集和测试集的logger\n",
    "train_logger = SummaryWriter(log_dir='logs/train')\n",
    "test_logger = SummaryWriter(log_dir='logs/test')\n",
    "# # 训练模型\n",
    "# for epoch in range(num_epochs):\n",
    "#     running_loss = 0.0\n",
    "#     # correct = 0 \n",
    "#     # total = 0\n",
    "#     for i, (images, labels) in enumerate(train_loader):\n",
    "#         images = images.to('cuda')\n",
    "#         labels = labels.to('cuda')\n",
    "        \n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(images)\n",
    "#         loss = criterion(outputs, labels)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         running_loss += loss.item()\n",
    "#         if (i+1) % 10 == 0:\n",
    "#             print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {running_loss/10:.4f}')\n",
    "#             # 将训练集的loss写入TensorBoard\n",
    "#             train_logger.add_scalar('loss', running_loss, epoch)\n",
    "#             running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [10/399], Loss: 0.8008, Acc: 0.6250\n",
      "Epoch [1/10], Step [20/399], Loss: 0.3765, Acc: 0.8812\n",
      "Epoch [1/10], Step [30/399], Loss: 0.3711, Acc: 0.8438\n",
      "Epoch [1/10], Step [40/399], Loss: 0.3688, Acc: 0.8688\n",
      "Epoch [1/10], Step [50/399], Loss: 0.5516, Acc: 0.7125\n",
      "Epoch [1/10], Step [60/399], Loss: 0.3942, Acc: 0.8562\n",
      "Epoch [1/10], Step [70/399], Loss: 0.3561, Acc: 0.8750\n",
      "Epoch [1/10], Step [80/399], Loss: 0.3091, Acc: 0.8750\n",
      "Epoch [1/10], Step [90/399], Loss: 0.4714, Acc: 0.8500\n",
      "Epoch [1/10], Step [100/399], Loss: 0.4802, Acc: 0.8187\n",
      "Epoch [1/10], Step [110/399], Loss: 0.4285, Acc: 0.8250\n",
      "Epoch [1/10], Step [120/399], Loss: 0.4111, Acc: 0.8500\n",
      "Epoch [1/10], Step [130/399], Loss: 0.4403, Acc: 0.8250\n",
      "Epoch [1/10], Step [140/399], Loss: 0.4777, Acc: 0.7688\n",
      "Epoch [1/10], Step [150/399], Loss: 0.4328, Acc: 0.8187\n",
      "Epoch [1/10], Step [160/399], Loss: 0.3905, Acc: 0.8562\n",
      "Epoch [1/10], Step [170/399], Loss: 0.4416, Acc: 0.8187\n",
      "Epoch [1/10], Step [180/399], Loss: 0.5147, Acc: 0.7875\n",
      "Epoch [1/10], Step [190/399], Loss: 0.4238, Acc: 0.8125\n",
      "Epoch [1/10], Step [200/399], Loss: 0.4264, Acc: 0.8063\n",
      "Epoch [1/10], Step [210/399], Loss: 0.4137, Acc: 0.8313\n",
      "Epoch [1/10], Step [220/399], Loss: 0.3840, Acc: 0.8438\n",
      "Epoch [1/10], Step [230/399], Loss: 0.3164, Acc: 0.8875\n",
      "Epoch [1/10], Step [240/399], Loss: 0.3761, Acc: 0.8688\n",
      "Epoch [1/10], Step [250/399], Loss: 0.4046, Acc: 0.8438\n",
      "Epoch [1/10], Step [260/399], Loss: 0.3618, Acc: 0.8688\n",
      "Epoch [1/10], Step [270/399], Loss: 0.3542, Acc: 0.8562\n",
      "Epoch [1/10], Step [280/399], Loss: 0.2331, Acc: 0.9437\n",
      "Epoch [1/10], Step [290/399], Loss: 0.3606, Acc: 0.8438\n",
      "Epoch [1/10], Step [300/399], Loss: 0.4090, Acc: 0.8625\n",
      "Epoch [1/10], Step [310/399], Loss: 0.3505, Acc: 0.8812\n",
      "Epoch [1/10], Step [320/399], Loss: 0.3491, Acc: 0.8313\n",
      "Epoch [1/10], Step [330/399], Loss: 0.5317, Acc: 0.7562\n",
      "Epoch [1/10], Step [340/399], Loss: 0.3212, Acc: 0.8812\n",
      "Epoch [1/10], Step [350/399], Loss: 0.3731, Acc: 0.8688\n",
      "Epoch [1/10], Step [360/399], Loss: 0.2754, Acc: 0.9125\n",
      "Epoch [1/10], Step [370/399], Loss: 0.3811, Acc: 0.8812\n",
      "Epoch [1/10], Step [380/399], Loss: 0.4536, Acc: 0.8313\n",
      "Epoch [1/10], Step [390/399], Loss: 0.4296, Acc: 0.7875\n",
      "Epoch [2/10], Step [10/399], Loss: 0.3754, Acc: 0.8562\n",
      "Epoch [2/10], Step [20/399], Loss: 0.4183, Acc: 0.7875\n",
      "Epoch [2/10], Step [30/399], Loss: 0.3927, Acc: 0.8063\n",
      "Epoch [2/10], Step [40/399], Loss: 0.3367, Acc: 0.8938\n",
      "Epoch [2/10], Step [50/399], Loss: 0.3280, Acc: 0.8875\n",
      "Epoch [2/10], Step [60/399], Loss: 0.3605, Acc: 0.8875\n",
      "Epoch [2/10], Step [70/399], Loss: 0.2737, Acc: 0.9187\n",
      "Epoch [2/10], Step [80/399], Loss: 0.3300, Acc: 0.9000\n",
      "Epoch [2/10], Step [90/399], Loss: 0.2578, Acc: 0.9375\n",
      "Epoch [2/10], Step [100/399], Loss: 0.3027, Acc: 0.8812\n",
      "Epoch [2/10], Step [110/399], Loss: 0.2998, Acc: 0.9125\n",
      "Epoch [2/10], Step [120/399], Loss: 0.4117, Acc: 0.8438\n",
      "Epoch [2/10], Step [130/399], Loss: 0.2986, Acc: 0.8750\n",
      "Epoch [2/10], Step [140/399], Loss: 0.2950, Acc: 0.8875\n",
      "Epoch [2/10], Step [150/399], Loss: 0.2289, Acc: 0.9313\n",
      "Epoch [2/10], Step [160/399], Loss: 0.2167, Acc: 0.9187\n",
      "Epoch [2/10], Step [170/399], Loss: 0.2788, Acc: 0.9125\n",
      "Epoch [2/10], Step [180/399], Loss: 0.2989, Acc: 0.9000\n",
      "Epoch [2/10], Step [190/399], Loss: 0.2836, Acc: 0.9000\n",
      "Epoch [2/10], Step [200/399], Loss: 0.3887, Acc: 0.8750\n",
      "Epoch [2/10], Step [210/399], Loss: 0.2794, Acc: 0.9062\n",
      "Epoch [2/10], Step [220/399], Loss: 0.3553, Acc: 0.8313\n",
      "Epoch [2/10], Step [230/399], Loss: 0.3022, Acc: 0.8812\n",
      "Epoch [2/10], Step [240/399], Loss: 0.1713, Acc: 0.9500\n",
      "Epoch [2/10], Step [250/399], Loss: 0.3414, Acc: 0.9187\n",
      "Epoch [2/10], Step [260/399], Loss: 0.3155, Acc: 0.8938\n",
      "Epoch [2/10], Step [270/399], Loss: 0.2487, Acc: 0.9000\n",
      "Epoch [2/10], Step [280/399], Loss: 0.3554, Acc: 0.8938\n",
      "Epoch [2/10], Step [290/399], Loss: 0.2855, Acc: 0.9187\n",
      "Epoch [2/10], Step [300/399], Loss: 0.3568, Acc: 0.8438\n",
      "Epoch [2/10], Step [310/399], Loss: 0.2855, Acc: 0.9187\n",
      "Epoch [2/10], Step [320/399], Loss: 0.3124, Acc: 0.8125\n",
      "Epoch [2/10], Step [330/399], Loss: 0.2694, Acc: 0.9375\n",
      "Epoch [2/10], Step [340/399], Loss: 0.1977, Acc: 0.9625\n",
      "Epoch [2/10], Step [350/399], Loss: 0.3327, Acc: 0.9062\n",
      "Epoch [2/10], Step [360/399], Loss: 0.3011, Acc: 0.9000\n",
      "Epoch [2/10], Step [370/399], Loss: 0.2759, Acc: 0.8938\n",
      "Epoch [2/10], Step [380/399], Loss: 0.2557, Acc: 0.8500\n",
      "Epoch [2/10], Step [390/399], Loss: 0.2583, Acc: 0.9187\n",
      "Epoch [3/10], Step [10/399], Loss: 0.3476, Acc: 0.8688\n",
      "Epoch [3/10], Step [20/399], Loss: 0.4298, Acc: 0.8313\n",
      "Epoch [3/10], Step [30/399], Loss: 0.3069, Acc: 0.8938\n",
      "Epoch [3/10], Step [40/399], Loss: 0.2442, Acc: 0.9187\n",
      "Epoch [3/10], Step [50/399], Loss: 0.2339, Acc: 0.8938\n",
      "Epoch [3/10], Step [60/399], Loss: 0.1735, Acc: 0.9563\n",
      "Epoch [3/10], Step [70/399], Loss: 0.3933, Acc: 0.9000\n",
      "Epoch [3/10], Step [80/399], Loss: 0.2430, Acc: 0.9187\n",
      "Epoch [3/10], Step [90/399], Loss: 0.2740, Acc: 0.8812\n",
      "Epoch [3/10], Step [100/399], Loss: 0.2668, Acc: 0.9250\n",
      "Epoch [3/10], Step [110/399], Loss: 0.3244, Acc: 0.8688\n",
      "Epoch [3/10], Step [120/399], Loss: 0.3139, Acc: 0.9000\n",
      "Epoch [3/10], Step [130/399], Loss: 0.3566, Acc: 0.8688\n",
      "Epoch [3/10], Step [140/399], Loss: 0.1724, Acc: 0.9563\n",
      "Epoch [3/10], Step [150/399], Loss: 0.3815, Acc: 0.8562\n",
      "Epoch [3/10], Step [160/399], Loss: 0.2121, Acc: 0.9375\n",
      "Epoch [3/10], Step [170/399], Loss: 0.2151, Acc: 0.9250\n",
      "Epoch [3/10], Step [180/399], Loss: 0.2701, Acc: 0.8688\n",
      "Epoch [3/10], Step [190/399], Loss: 0.2477, Acc: 0.9375\n",
      "Epoch [3/10], Step [200/399], Loss: 0.2383, Acc: 0.9250\n",
      "Epoch [3/10], Step [210/399], Loss: 0.3994, Acc: 0.8500\n",
      "Epoch [3/10], Step [220/399], Loss: 0.2903, Acc: 0.9000\n",
      "Epoch [3/10], Step [230/399], Loss: 0.2971, Acc: 0.8750\n",
      "Epoch [3/10], Step [240/399], Loss: 0.3781, Acc: 0.8750\n",
      "Epoch [3/10], Step [250/399], Loss: 0.3120, Acc: 0.8625\n",
      "Epoch [3/10], Step [260/399], Loss: 0.2507, Acc: 0.9250\n",
      "Epoch [3/10], Step [270/399], Loss: 0.4166, Acc: 0.8438\n",
      "Epoch [3/10], Step [280/399], Loss: 0.2857, Acc: 0.9062\n",
      "Epoch [3/10], Step [290/399], Loss: 0.3376, Acc: 0.8750\n",
      "Epoch [3/10], Step [300/399], Loss: 0.1974, Acc: 0.9563\n",
      "Epoch [3/10], Step [310/399], Loss: 0.2507, Acc: 0.9375\n",
      "Epoch [3/10], Step [320/399], Loss: 0.5136, Acc: 0.8313\n",
      "Epoch [3/10], Step [330/399], Loss: 0.2369, Acc: 0.9375\n",
      "Epoch [3/10], Step [340/399], Loss: 0.4362, Acc: 0.8688\n",
      "Epoch [3/10], Step [350/399], Loss: 0.2815, Acc: 0.9250\n",
      "Epoch [3/10], Step [360/399], Loss: 0.2901, Acc: 0.9125\n",
      "Epoch [3/10], Step [370/399], Loss: 0.3788, Acc: 0.8750\n",
      "Epoch [3/10], Step [380/399], Loss: 0.2858, Acc: 0.9000\n",
      "Epoch [3/10], Step [390/399], Loss: 0.3249, Acc: 0.8938\n",
      "Epoch [4/10], Step [10/399], Loss: 0.2708, Acc: 0.8812\n",
      "Epoch [4/10], Step [20/399], Loss: 0.2953, Acc: 0.8938\n",
      "Epoch [4/10], Step [30/399], Loss: 0.2841, Acc: 0.9000\n",
      "Epoch [4/10], Step [40/399], Loss: 0.3413, Acc: 0.8750\n",
      "Epoch [4/10], Step [50/399], Loss: 0.3410, Acc: 0.8187\n",
      "Epoch [4/10], Step [60/399], Loss: 0.2590, Acc: 0.8938\n",
      "Epoch [4/10], Step [70/399], Loss: 0.3324, Acc: 0.8625\n",
      "Epoch [4/10], Step [80/399], Loss: 0.3037, Acc: 0.9062\n",
      "Epoch [4/10], Step [90/399], Loss: 0.2694, Acc: 0.9062\n",
      "Epoch [4/10], Step [100/399], Loss: 0.3019, Acc: 0.9125\n",
      "Epoch [4/10], Step [110/399], Loss: 0.2532, Acc: 0.9000\n",
      "Epoch [4/10], Step [120/399], Loss: 0.3199, Acc: 0.9062\n",
      "Epoch [4/10], Step [130/399], Loss: 0.2562, Acc: 0.8812\n",
      "Epoch [4/10], Step [140/399], Loss: 0.3431, Acc: 0.8812\n",
      "Epoch [4/10], Step [150/399], Loss: 0.3133, Acc: 0.8938\n",
      "Epoch [4/10], Step [160/399], Loss: 0.3100, Acc: 0.8875\n",
      "Epoch [4/10], Step [170/399], Loss: 0.2524, Acc: 0.9062\n",
      "Epoch [4/10], Step [180/399], Loss: 0.2806, Acc: 0.9313\n",
      "Epoch [4/10], Step [190/399], Loss: 0.3081, Acc: 0.8812\n",
      "Epoch [4/10], Step [200/399], Loss: 0.2901, Acc: 0.9125\n",
      "Epoch [4/10], Step [210/399], Loss: 0.2212, Acc: 0.9313\n",
      "Epoch [4/10], Step [220/399], Loss: 0.2021, Acc: 0.9313\n",
      "Epoch [4/10], Step [230/399], Loss: 0.3513, Acc: 0.8375\n",
      "Epoch [4/10], Step [240/399], Loss: 0.2826, Acc: 0.8938\n",
      "Epoch [4/10], Step [250/399], Loss: 0.2525, Acc: 0.9062\n",
      "Epoch [4/10], Step [260/399], Loss: 0.3019, Acc: 0.8812\n",
      "Epoch [4/10], Step [270/399], Loss: 0.2802, Acc: 0.9125\n",
      "Epoch [4/10], Step [280/399], Loss: 0.2357, Acc: 0.9250\n",
      "Epoch [4/10], Step [290/399], Loss: 0.3400, Acc: 0.8250\n",
      "Epoch [4/10], Step [300/399], Loss: 0.3018, Acc: 0.8938\n",
      "Epoch [4/10], Step [310/399], Loss: 0.2728, Acc: 0.9062\n",
      "Epoch [4/10], Step [320/399], Loss: 0.2393, Acc: 0.8938\n",
      "Epoch [4/10], Step [330/399], Loss: 0.3021, Acc: 0.8938\n",
      "Epoch [4/10], Step [340/399], Loss: 0.2621, Acc: 0.9187\n",
      "Epoch [4/10], Step [350/399], Loss: 0.2065, Acc: 0.9313\n",
      "Epoch [4/10], Step [360/399], Loss: 0.2615, Acc: 0.9125\n",
      "Epoch [4/10], Step [370/399], Loss: 0.2337, Acc: 0.9313\n",
      "Epoch [4/10], Step [380/399], Loss: 0.1954, Acc: 0.9062\n",
      "Epoch [4/10], Step [390/399], Loss: 0.1467, Acc: 0.9563\n",
      "Epoch [5/10], Step [10/399], Loss: 0.1796, Acc: 0.9375\n",
      "Epoch [5/10], Step [20/399], Loss: 0.2906, Acc: 0.9125\n",
      "Epoch [5/10], Step [30/399], Loss: 0.3423, Acc: 0.8625\n",
      "Epoch [5/10], Step [40/399], Loss: 0.3608, Acc: 0.8750\n",
      "Epoch [5/10], Step [50/399], Loss: 0.3795, Acc: 0.8562\n",
      "Epoch [5/10], Step [60/399], Loss: 0.2333, Acc: 0.9313\n",
      "Epoch [5/10], Step [70/399], Loss: 0.2039, Acc: 0.9375\n",
      "Epoch [5/10], Step [80/399], Loss: 0.3508, Acc: 0.8875\n",
      "Epoch [5/10], Step [90/399], Loss: 0.2416, Acc: 0.9313\n",
      "Epoch [5/10], Step [100/399], Loss: 0.1632, Acc: 0.9625\n",
      "Epoch [5/10], Step [110/399], Loss: 0.2763, Acc: 0.9062\n",
      "Epoch [5/10], Step [120/399], Loss: 0.2864, Acc: 0.8938\n",
      "Epoch [5/10], Step [130/399], Loss: 0.3220, Acc: 0.8938\n",
      "Epoch [5/10], Step [140/399], Loss: 0.2934, Acc: 0.9250\n",
      "Epoch [5/10], Step [150/399], Loss: 0.2768, Acc: 0.9062\n",
      "Epoch [5/10], Step [160/399], Loss: 0.2358, Acc: 0.9250\n",
      "Epoch [5/10], Step [170/399], Loss: 0.2417, Acc: 0.9187\n",
      "Epoch [5/10], Step [180/399], Loss: 0.2265, Acc: 0.9187\n",
      "Epoch [5/10], Step [190/399], Loss: 0.2430, Acc: 0.9062\n",
      "Epoch [5/10], Step [200/399], Loss: 0.3060, Acc: 0.8688\n",
      "Epoch [5/10], Step [210/399], Loss: 0.3518, Acc: 0.8750\n",
      "Epoch [5/10], Step [220/399], Loss: 0.2479, Acc: 0.8750\n",
      "Epoch [5/10], Step [230/399], Loss: 0.2655, Acc: 0.9313\n",
      "Epoch [5/10], Step [240/399], Loss: 0.2877, Acc: 0.8938\n",
      "Epoch [5/10], Step [250/399], Loss: 0.2981, Acc: 0.9062\n",
      "Epoch [5/10], Step [260/399], Loss: 0.2709, Acc: 0.9313\n",
      "Epoch [5/10], Step [270/399], Loss: 0.3660, Acc: 0.8313\n",
      "Epoch [5/10], Step [280/399], Loss: 0.2741, Acc: 0.9000\n",
      "Epoch [5/10], Step [290/399], Loss: 0.2361, Acc: 0.9187\n",
      "Epoch [5/10], Step [300/399], Loss: 0.2895, Acc: 0.9000\n",
      "Epoch [5/10], Step [310/399], Loss: 0.2253, Acc: 0.9125\n",
      "Epoch [5/10], Step [320/399], Loss: 0.1984, Acc: 0.9437\n",
      "Epoch [5/10], Step [330/399], Loss: 0.3740, Acc: 0.8562\n",
      "Epoch [5/10], Step [340/399], Loss: 0.3062, Acc: 0.9000\n",
      "Epoch [5/10], Step [350/399], Loss: 0.2757, Acc: 0.9125\n",
      "Epoch [5/10], Step [360/399], Loss: 0.3052, Acc: 0.8688\n",
      "Epoch [5/10], Step [370/399], Loss: 0.2563, Acc: 0.9187\n",
      "Epoch [5/10], Step [380/399], Loss: 0.1317, Acc: 0.9688\n",
      "Epoch [5/10], Step [390/399], Loss: 0.2858, Acc: 0.9062\n",
      "Epoch [6/10], Step [10/399], Loss: 0.2432, Acc: 0.9375\n",
      "Epoch [6/10], Step [20/399], Loss: 0.2337, Acc: 0.9375\n",
      "Epoch [6/10], Step [30/399], Loss: 0.3118, Acc: 0.8938\n",
      "Epoch [6/10], Step [40/399], Loss: 0.2269, Acc: 0.9000\n",
      "Epoch [6/10], Step [50/399], Loss: 0.2887, Acc: 0.9062\n",
      "Epoch [6/10], Step [60/399], Loss: 0.2286, Acc: 0.9313\n",
      "Epoch [6/10], Step [70/399], Loss: 0.2549, Acc: 0.9187\n",
      "Epoch [6/10], Step [80/399], Loss: 0.2669, Acc: 0.9125\n",
      "Epoch [6/10], Step [90/399], Loss: 0.3270, Acc: 0.9062\n",
      "Epoch [6/10], Step [100/399], Loss: 0.3798, Acc: 0.8375\n",
      "Epoch [6/10], Step [110/399], Loss: 0.2338, Acc: 0.9250\n",
      "Epoch [6/10], Step [120/399], Loss: 0.3036, Acc: 0.8750\n",
      "Epoch [6/10], Step [130/399], Loss: 0.2549, Acc: 0.8812\n",
      "Epoch [6/10], Step [140/399], Loss: 0.3832, Acc: 0.9000\n",
      "Epoch [6/10], Step [150/399], Loss: 0.1701, Acc: 0.9500\n",
      "Epoch [6/10], Step [160/399], Loss: 0.3310, Acc: 0.8938\n",
      "Epoch [6/10], Step [170/399], Loss: 0.2365, Acc: 0.9125\n",
      "Epoch [6/10], Step [180/399], Loss: 0.1893, Acc: 0.9500\n",
      "Epoch [6/10], Step [190/399], Loss: 0.3055, Acc: 0.8875\n",
      "Epoch [6/10], Step [200/399], Loss: 0.2906, Acc: 0.9062\n",
      "Epoch [6/10], Step [210/399], Loss: 0.3041, Acc: 0.8625\n",
      "Epoch [6/10], Step [220/399], Loss: 0.1418, Acc: 0.9688\n",
      "Epoch [6/10], Step [230/399], Loss: 0.3287, Acc: 0.8688\n",
      "Epoch [6/10], Step [240/399], Loss: 0.2258, Acc: 0.9250\n",
      "Epoch [6/10], Step [250/399], Loss: 0.2149, Acc: 0.9500\n",
      "Epoch [6/10], Step [260/399], Loss: 0.2346, Acc: 0.9250\n",
      "Epoch [6/10], Step [270/399], Loss: 0.1576, Acc: 0.9688\n",
      "Epoch [6/10], Step [280/399], Loss: 0.2583, Acc: 0.9250\n",
      "Epoch [6/10], Step [290/399], Loss: 0.3319, Acc: 0.8750\n",
      "Epoch [6/10], Step [300/399], Loss: 0.2464, Acc: 0.9125\n",
      "Epoch [6/10], Step [310/399], Loss: 0.3580, Acc: 0.9000\n",
      "Epoch [6/10], Step [320/399], Loss: 0.2650, Acc: 0.8938\n",
      "Epoch [6/10], Step [330/399], Loss: 0.2667, Acc: 0.9125\n",
      "Epoch [6/10], Step [340/399], Loss: 0.2797, Acc: 0.8875\n",
      "Epoch [6/10], Step [350/399], Loss: 0.4270, Acc: 0.8438\n",
      "Epoch [6/10], Step [360/399], Loss: 0.2252, Acc: 0.9437\n",
      "Epoch [6/10], Step [370/399], Loss: 0.3222, Acc: 0.8938\n",
      "Epoch [6/10], Step [380/399], Loss: 0.2519, Acc: 0.8812\n",
      "Epoch [6/10], Step [390/399], Loss: 0.3117, Acc: 0.8875\n",
      "Epoch [7/10], Step [10/399], Loss: 0.2602, Acc: 0.9375\n",
      "Epoch [7/10], Step [20/399], Loss: 0.2119, Acc: 0.9250\n",
      "Epoch [7/10], Step [30/399], Loss: 0.3061, Acc: 0.9000\n",
      "Epoch [7/10], Step [40/399], Loss: 0.2083, Acc: 0.9437\n",
      "Epoch [7/10], Step [50/399], Loss: 0.1702, Acc: 0.9625\n",
      "Epoch [7/10], Step [60/399], Loss: 0.3109, Acc: 0.9187\n",
      "Epoch [7/10], Step [70/399], Loss: 0.3439, Acc: 0.8750\n",
      "Epoch [7/10], Step [80/399], Loss: 0.3084, Acc: 0.9125\n",
      "Epoch [7/10], Step [90/399], Loss: 0.3278, Acc: 0.8938\n",
      "Epoch [7/10], Step [100/399], Loss: 0.2832, Acc: 0.9000\n",
      "Epoch [7/10], Step [110/399], Loss: 0.2103, Acc: 0.9437\n",
      "Epoch [7/10], Step [120/399], Loss: 0.2248, Acc: 0.9375\n",
      "Epoch [7/10], Step [130/399], Loss: 0.2634, Acc: 0.9250\n",
      "Epoch [7/10], Step [140/399], Loss: 0.2844, Acc: 0.8938\n",
      "Epoch [7/10], Step [150/399], Loss: 0.2346, Acc: 0.9313\n",
      "Epoch [7/10], Step [160/399], Loss: 0.2622, Acc: 0.9000\n",
      "Epoch [7/10], Step [170/399], Loss: 0.3219, Acc: 0.8812\n",
      "Epoch [7/10], Step [180/399], Loss: 0.3387, Acc: 0.8562\n",
      "Epoch [7/10], Step [190/399], Loss: 0.2440, Acc: 0.9187\n",
      "Epoch [7/10], Step [200/399], Loss: 0.2513, Acc: 0.9000\n",
      "Epoch [7/10], Step [210/399], Loss: 0.2175, Acc: 0.9250\n",
      "Epoch [7/10], Step [220/399], Loss: 0.2716, Acc: 0.9250\n",
      "Epoch [7/10], Step [230/399], Loss: 0.4217, Acc: 0.8812\n",
      "Epoch [7/10], Step [240/399], Loss: 0.2676, Acc: 0.9062\n",
      "Epoch [7/10], Step [250/399], Loss: 0.1779, Acc: 0.9375\n",
      "Epoch [7/10], Step [260/399], Loss: 0.3430, Acc: 0.9062\n",
      "Epoch [7/10], Step [270/399], Loss: 0.2505, Acc: 0.9375\n",
      "Epoch [7/10], Step [280/399], Loss: 0.2571, Acc: 0.9062\n",
      "Epoch [7/10], Step [290/399], Loss: 0.2153, Acc: 0.9250\n",
      "Epoch [7/10], Step [300/399], Loss: 0.2651, Acc: 0.9125\n",
      "Epoch [7/10], Step [310/399], Loss: 0.3039, Acc: 0.9125\n",
      "Epoch [7/10], Step [320/399], Loss: 0.3221, Acc: 0.8688\n",
      "Epoch [7/10], Step [330/399], Loss: 0.2225, Acc: 0.9375\n",
      "Epoch [7/10], Step [340/399], Loss: 0.2575, Acc: 0.9187\n",
      "Epoch [7/10], Step [350/399], Loss: 0.2230, Acc: 0.9250\n",
      "Epoch [7/10], Step [360/399], Loss: 0.2501, Acc: 0.8938\n",
      "Epoch [7/10], Step [370/399], Loss: 0.2258, Acc: 0.9250\n",
      "Epoch [7/10], Step [380/399], Loss: 0.2135, Acc: 0.9375\n",
      "Epoch [7/10], Step [390/399], Loss: 0.2816, Acc: 0.9000\n",
      "Epoch [8/10], Step [10/399], Loss: 0.2406, Acc: 0.9250\n",
      "Epoch [8/10], Step [20/399], Loss: 0.2667, Acc: 0.9313\n",
      "Epoch [8/10], Step [30/399], Loss: 0.2850, Acc: 0.9062\n",
      "Epoch [8/10], Step [40/399], Loss: 0.2933, Acc: 0.8938\n",
      "Epoch [8/10], Step [50/399], Loss: 0.2492, Acc: 0.8562\n",
      "Epoch [8/10], Step [60/399], Loss: 0.2924, Acc: 0.9313\n",
      "Epoch [8/10], Step [70/399], Loss: 0.2614, Acc: 0.9125\n",
      "Epoch [8/10], Step [80/399], Loss: 0.2142, Acc: 0.9062\n",
      "Epoch [8/10], Step [90/399], Loss: 0.3263, Acc: 0.8812\n",
      "Epoch [8/10], Step [100/399], Loss: 0.2891, Acc: 0.9187\n",
      "Epoch [8/10], Step [110/399], Loss: 0.3046, Acc: 0.9062\n",
      "Epoch [8/10], Step [120/399], Loss: 0.2523, Acc: 0.9187\n",
      "Epoch [8/10], Step [130/399], Loss: 0.3008, Acc: 0.8812\n",
      "Epoch [8/10], Step [140/399], Loss: 0.1707, Acc: 0.9625\n",
      "Epoch [8/10], Step [150/399], Loss: 0.3666, Acc: 0.8875\n",
      "Epoch [8/10], Step [160/399], Loss: 0.2678, Acc: 0.8938\n",
      "Epoch [8/10], Step [170/399], Loss: 0.2968, Acc: 0.8375\n",
      "Epoch [8/10], Step [180/399], Loss: 0.1979, Acc: 0.9313\n",
      "Epoch [8/10], Step [190/399], Loss: 0.3448, Acc: 0.8750\n",
      "Epoch [8/10], Step [200/399], Loss: 0.2556, Acc: 0.9187\n",
      "Epoch [8/10], Step [210/399], Loss: 0.2080, Acc: 0.9375\n",
      "Epoch [8/10], Step [220/399], Loss: 0.2532, Acc: 0.9125\n",
      "Epoch [8/10], Step [230/399], Loss: 0.2215, Acc: 0.9375\n",
      "Epoch [8/10], Step [240/399], Loss: 0.2375, Acc: 0.9187\n",
      "Epoch [8/10], Step [250/399], Loss: 0.3478, Acc: 0.8812\n",
      "Epoch [8/10], Step [260/399], Loss: 0.2001, Acc: 0.9500\n",
      "Epoch [8/10], Step [270/399], Loss: 0.2600, Acc: 0.9062\n",
      "Epoch [8/10], Step [280/399], Loss: 0.2272, Acc: 0.9125\n",
      "Epoch [8/10], Step [290/399], Loss: 0.2360, Acc: 0.9313\n",
      "Epoch [8/10], Step [300/399], Loss: 0.1867, Acc: 0.9375\n",
      "Epoch [8/10], Step [310/399], Loss: 0.2768, Acc: 0.9000\n",
      "Epoch [8/10], Step [320/399], Loss: 0.3288, Acc: 0.8875\n",
      "Epoch [8/10], Step [330/399], Loss: 0.2519, Acc: 0.9375\n",
      "Epoch [8/10], Step [340/399], Loss: 0.3132, Acc: 0.8875\n",
      "Epoch [8/10], Step [350/399], Loss: 0.2356, Acc: 0.9250\n",
      "Epoch [8/10], Step [360/399], Loss: 0.2392, Acc: 0.9313\n",
      "Epoch [8/10], Step [370/399], Loss: 0.2424, Acc: 0.9125\n",
      "Epoch [8/10], Step [380/399], Loss: 0.1965, Acc: 0.9563\n",
      "Epoch [8/10], Step [390/399], Loss: 0.2663, Acc: 0.8500\n",
      "Epoch [9/10], Step [10/399], Loss: 0.3067, Acc: 0.8313\n",
      "Epoch [9/10], Step [20/399], Loss: 0.3228, Acc: 0.8812\n",
      "Epoch [9/10], Step [30/399], Loss: 0.2061, Acc: 0.9437\n",
      "Epoch [9/10], Step [40/399], Loss: 0.2757, Acc: 0.9000\n",
      "Epoch [9/10], Step [50/399], Loss: 0.2886, Acc: 0.8875\n",
      "Epoch [9/10], Step [60/399], Loss: 0.1251, Acc: 0.9625\n",
      "Epoch [9/10], Step [70/399], Loss: 0.2362, Acc: 0.9375\n",
      "Epoch [9/10], Step [80/399], Loss: 0.1844, Acc: 0.9437\n",
      "Epoch [9/10], Step [90/399], Loss: 0.2042, Acc: 0.9375\n",
      "Epoch [9/10], Step [100/399], Loss: 0.2068, Acc: 0.9437\n",
      "Epoch [9/10], Step [110/399], Loss: 0.2752, Acc: 0.9250\n",
      "Epoch [9/10], Step [120/399], Loss: 0.3056, Acc: 0.8750\n",
      "Epoch [9/10], Step [130/399], Loss: 0.2235, Acc: 0.9250\n",
      "Epoch [9/10], Step [140/399], Loss: 0.3473, Acc: 0.8562\n",
      "Epoch [9/10], Step [150/399], Loss: 0.3084, Acc: 0.9062\n",
      "Epoch [9/10], Step [160/399], Loss: 0.1663, Acc: 0.9625\n",
      "Epoch [9/10], Step [170/399], Loss: 0.2249, Acc: 0.9062\n",
      "Epoch [9/10], Step [180/399], Loss: 0.2593, Acc: 0.9062\n",
      "Epoch [9/10], Step [190/399], Loss: 0.2994, Acc: 0.9250\n",
      "Epoch [9/10], Step [200/399], Loss: 0.2851, Acc: 0.8938\n",
      "Epoch [9/10], Step [210/399], Loss: 0.2528, Acc: 0.9250\n",
      "Epoch [9/10], Step [220/399], Loss: 0.2759, Acc: 0.9125\n",
      "Epoch [9/10], Step [230/399], Loss: 0.2283, Acc: 0.9313\n",
      "Epoch [9/10], Step [240/399], Loss: 0.2440, Acc: 0.9437\n",
      "Epoch [9/10], Step [250/399], Loss: 0.1807, Acc: 0.9437\n",
      "Epoch [9/10], Step [260/399], Loss: 0.2378, Acc: 0.9313\n",
      "Epoch [9/10], Step [270/399], Loss: 0.2706, Acc: 0.9000\n",
      "Epoch [9/10], Step [280/399], Loss: 0.2375, Acc: 0.9187\n",
      "Epoch [9/10], Step [290/399], Loss: 0.2347, Acc: 0.9313\n",
      "Epoch [9/10], Step [300/399], Loss: 0.1935, Acc: 0.9437\n",
      "Epoch [9/10], Step [310/399], Loss: 0.2486, Acc: 0.9000\n",
      "Epoch [9/10], Step [320/399], Loss: 0.3648, Acc: 0.8812\n",
      "Epoch [9/10], Step [330/399], Loss: 0.2261, Acc: 0.9313\n",
      "Epoch [9/10], Step [340/399], Loss: 0.2515, Acc: 0.9187\n",
      "Epoch [9/10], Step [350/399], Loss: 0.3959, Acc: 0.8375\n",
      "Epoch [9/10], Step [360/399], Loss: 0.2266, Acc: 0.9313\n",
      "Epoch [9/10], Step [370/399], Loss: 0.2675, Acc: 0.9062\n",
      "Epoch [9/10], Step [380/399], Loss: 0.2497, Acc: 0.9250\n",
      "Epoch [9/10], Step [390/399], Loss: 0.2554, Acc: 0.9062\n",
      "Epoch [10/10], Step [10/399], Loss: 0.2284, Acc: 0.9437\n",
      "Epoch [10/10], Step [20/399], Loss: 0.3107, Acc: 0.9125\n",
      "Epoch [10/10], Step [30/399], Loss: 0.1718, Acc: 0.9625\n",
      "Epoch [10/10], Step [40/399], Loss: 0.3492, Acc: 0.8875\n",
      "Epoch [10/10], Step [50/399], Loss: 0.2588, Acc: 0.9250\n",
      "Epoch [10/10], Step [60/399], Loss: 0.2199, Acc: 0.9437\n",
      "Epoch [10/10], Step [70/399], Loss: 0.2332, Acc: 0.9313\n",
      "Epoch [10/10], Step [80/399], Loss: 0.2939, Acc: 0.8812\n",
      "Epoch [10/10], Step [90/399], Loss: 0.3212, Acc: 0.8812\n",
      "Epoch [10/10], Step [100/399], Loss: 0.1737, Acc: 0.9563\n",
      "Epoch [10/10], Step [110/399], Loss: 0.2274, Acc: 0.9187\n",
      "Epoch [10/10], Step [120/399], Loss: 0.2393, Acc: 0.9187\n",
      "Epoch [10/10], Step [130/399], Loss: 0.2652, Acc: 0.8938\n",
      "Epoch [10/10], Step [140/399], Loss: 0.1569, Acc: 0.9625\n",
      "Epoch [10/10], Step [150/399], Loss: 0.2323, Acc: 0.9250\n",
      "Epoch [10/10], Step [160/399], Loss: 0.2320, Acc: 0.9125\n",
      "Epoch [10/10], Step [170/399], Loss: 0.2287, Acc: 0.9187\n",
      "Epoch [10/10], Step [180/399], Loss: 0.1531, Acc: 0.9688\n",
      "Epoch [10/10], Step [190/399], Loss: 0.2877, Acc: 0.9000\n",
      "Epoch [10/10], Step [200/399], Loss: 0.2614, Acc: 0.9187\n",
      "Epoch [10/10], Step [210/399], Loss: 0.2497, Acc: 0.9313\n",
      "Epoch [10/10], Step [220/399], Loss: 0.2499, Acc: 0.9125\n",
      "Epoch [10/10], Step [230/399], Loss: 0.3231, Acc: 0.8875\n",
      "Epoch [10/10], Step [240/399], Loss: 0.1499, Acc: 0.9750\n",
      "Epoch [10/10], Step [250/399], Loss: 0.2599, Acc: 0.9250\n",
      "Epoch [10/10], Step [260/399], Loss: 0.2384, Acc: 0.9437\n",
      "Epoch [10/10], Step [270/399], Loss: 0.2970, Acc: 0.9187\n",
      "Epoch [10/10], Step [280/399], Loss: 0.2404, Acc: 0.9250\n",
      "Epoch [10/10], Step [290/399], Loss: 0.2205, Acc: 0.9250\n",
      "Epoch [10/10], Step [300/399], Loss: 0.2490, Acc: 0.9125\n",
      "Epoch [10/10], Step [310/399], Loss: 0.2928, Acc: 0.9062\n",
      "Epoch [10/10], Step [320/399], Loss: 0.1639, Acc: 0.9563\n",
      "Epoch [10/10], Step [330/399], Loss: 0.3852, Acc: 0.8438\n",
      "Epoch [10/10], Step [340/399], Loss: 0.2506, Acc: 0.8750\n",
      "Epoch [10/10], Step [350/399], Loss: 0.2048, Acc: 0.9375\n",
      "Epoch [10/10], Step [360/399], Loss: 0.2084, Acc: 0.9375\n",
      "Epoch [10/10], Step [370/399], Loss: 0.2334, Acc: 0.9250\n",
      "Epoch [10/10], Step [380/399], Loss: 0.2658, Acc: 0.9000\n",
      "Epoch [10/10], Step [390/399], Loss: 0.2513, Acc: 0.9250\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0  # 初始化 running_acc 变量\n",
    "    # correct = 0 \n",
    "    # total = 0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to('cuda')\n",
    "        labels = labels.to('cuda')\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 计算准确率\n",
    "        predicted = torch.argmax(outputs, 1)\n",
    "        correct = (predicted == labels).sum().item()\n",
    "        total = labels.size(0)\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        running_acc += correct / total\n",
    "        \n",
    "        if (i+1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {running_loss/10:.4f}, Acc: {running_acc/10:.4f}')\n",
    "            # 将训练集的loss和acc写入TensorBoard\n",
    "            train_logger.add_scalar('loss', running_loss, epoch)\n",
    "            train_logger.add_scalar('acc', running_acc, epoch)\n",
    "            running_loss = 0.0\n",
    "            running_acc = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 16 test images: 100.0%\n",
      "Accuracy of the network on the 32 test images: 100.0%\n",
      "Accuracy of the network on the 48 test images: 97.91666666666667%\n",
      "Accuracy of the network on the 64 test images: 93.75%\n",
      "Accuracy of the network on the 80 test images: 93.75%\n",
      "Accuracy of the network on the 96 test images: 94.79166666666667%\n",
      "Accuracy of the network on the 112 test images: 93.75%\n",
      "Accuracy of the network on the 128 test images: 94.53125%\n",
      "Accuracy of the network on the 144 test images: 93.05555555555556%\n",
      "Accuracy of the network on the 160 test images: 92.5%\n",
      "Accuracy of the network on the 176 test images: 90.3409090909091%\n",
      "Accuracy of the network on the 192 test images: 90.625%\n",
      "Accuracy of the network on the 208 test images: 89.42307692307692%\n",
      "Accuracy of the network on the 224 test images: 89.28571428571429%\n",
      "Accuracy of the network on the 240 test images: 88.75%\n",
      "Accuracy of the network on the 256 test images: 85.546875%\n",
      "Accuracy of the network on the 272 test images: 85.66176470588235%\n",
      "Accuracy of the network on the 288 test images: 86.11111111111111%\n",
      "Accuracy of the network on the 304 test images: 85.85526315789474%\n",
      "Accuracy of the network on the 320 test images: 85.9375%\n",
      "Accuracy of the network on the 336 test images: 86.60714285714286%\n",
      "Accuracy of the network on the 352 test images: 86.93181818181819%\n",
      "Accuracy of the network on the 368 test images: 87.5%\n",
      "Accuracy of the network on the 384 test images: 87.5%\n",
      "Accuracy of the network on the 400 test images: 87.25%\n",
      "Accuracy of the network on the 416 test images: 87.01923076923077%\n",
      "Accuracy of the network on the 432 test images: 87.5%\n",
      "Accuracy of the network on the 448 test images: 87.94642857142857%\n",
      "Accuracy of the network on the 464 test images: 88.14655172413794%\n",
      "Accuracy of the network on the 480 test images: 87.70833333333333%\n",
      "Accuracy of the network on the 496 test images: 87.70161290322581%\n",
      "Accuracy of the network on the 512 test images: 88.0859375%\n",
      "Accuracy of the network on the 528 test images: 88.25757575757575%\n",
      "Accuracy of the network on the 544 test images: 88.6029411764706%\n",
      "Accuracy of the network on the 560 test images: 88.57142857142857%\n",
      "Accuracy of the network on the 576 test images: 88.71527777777777%\n",
      "Accuracy of the network on the 592 test images: 88.51351351351352%\n",
      "Accuracy of the network on the 608 test images: 88.15789473684211%\n",
      "Accuracy of the network on the 624 test images: 88.14102564102564%\n",
      "Accuracy of the network on the 640 test images: 88.28125%\n",
      "Accuracy of the network on the 656 test images: 88.41463414634147%\n",
      "Accuracy of the network on the 672 test images: 88.69047619047619%\n",
      "Accuracy of the network on the 688 test images: 88.80813953488372%\n",
      "Accuracy of the network on the 704 test images: 88.7784090909091%\n",
      "Accuracy of the network on the 720 test images: 88.88888888888889%\n",
      "Accuracy of the network on the 736 test images: 88.9945652173913%\n",
      "Accuracy of the network on the 752 test images: 88.9627659574468%\n",
      "Accuracy of the network on the 768 test images: 89.19270833333333%\n",
      "Accuracy of the network on the 784 test images: 89.15816326530613%\n",
      "Accuracy of the network on the 800 test images: 89.25%\n",
      "Accuracy of the network on the 816 test images: 89.33823529411765%\n",
      "Accuracy of the network on the 832 test images: 89.42307692307692%\n",
      "Accuracy of the network on the 848 test images: 88.91509433962264%\n",
      "Accuracy of the network on the 864 test images: 89.12037037037037%\n",
      "Accuracy of the network on the 880 test images: 88.4090909090909%\n",
      "Accuracy of the network on the 896 test images: 88.39285714285714%\n",
      "Accuracy of the network on the 912 test images: 88.48684210526316%\n",
      "Accuracy of the network on the 928 test images: 88.6853448275862%\n",
      "Accuracy of the network on the 944 test images: 88.87711864406779%\n",
      "Accuracy of the network on the 960 test images: 89.0625%\n",
      "Accuracy of the network on the 976 test images: 89.13934426229508%\n",
      "Accuracy of the network on the 992 test images: 89.11290322580645%\n",
      "Accuracy of the network on the 1008 test images: 89.08730158730158%\n",
      "Accuracy of the network on the 1024 test images: 89.0625%\n",
      "Accuracy of the network on the 1040 test images: 89.03846153846153%\n",
      "Accuracy of the network on the 1056 test images: 89.20454545454545%\n",
      "Accuracy of the network on the 1072 test images: 89.08582089552239%\n",
      "Accuracy of the network on the 1088 test images: 89.24632352941177%\n",
      "Accuracy of the network on the 1104 test images: 89.31159420289855%\n",
      "Accuracy of the network on the 1120 test images: 89.28571428571429%\n",
      "Accuracy of the network on the 1136 test images: 89.08450704225352%\n",
      "Accuracy of the network on the 1152 test images: 88.97569444444444%\n",
      "Accuracy of the network on the 1168 test images: 89.04109589041096%\n",
      "Accuracy of the network on the 1184 test images: 89.02027027027027%\n",
      "Accuracy of the network on the 1200 test images: 89.0%\n",
      "Accuracy of the network on the 1216 test images: 88.65131578947368%\n",
      "Accuracy of the network on the 1232 test images: 88.63636363636364%\n",
      "Accuracy of the network on the 1248 test images: 88.62179487179488%\n",
      "Accuracy of the network on the 1264 test images: 88.76582278481013%\n",
      "Accuracy of the network on the 1280 test images: 88.828125%\n",
      "Accuracy of the network on the 1296 test images: 88.96604938271605%\n",
      "Accuracy of the network on the 1312 test images: 89.02439024390245%\n",
      "Accuracy of the network on the 1328 test images: 88.93072289156626%\n",
      "Accuracy of the network on the 1344 test images: 88.83928571428571%\n",
      "Accuracy of the network on the 1360 test images: 88.30882352941177%\n",
      "Accuracy of the network on the 1376 test images: 88.29941860465117%\n",
      "Accuracy of the network on the 1392 test images: 88.29022988505747%\n",
      "Accuracy of the network on the 1408 test images: 88.35227272727273%\n",
      "Accuracy of the network on the 1424 test images: 88.41292134831461%\n",
      "Accuracy of the network on the 1440 test images: 88.40277777777777%\n",
      "Accuracy of the network on the 1456 test images: 88.46153846153847%\n",
      "Accuracy of the network on the 1472 test images: 88.51902173913044%\n",
      "Accuracy of the network on the 1488 test images: 88.44086021505376%\n",
      "Accuracy of the network on the 1504 test images: 88.56382978723404%\n",
      "Accuracy of the network on the 1520 test images: 88.61842105263158%\n",
      "Accuracy of the network on the 1536 test images: 88.54166666666667%\n",
      "Accuracy of the network on the 1552 test images: 88.59536082474227%\n",
      "Accuracy of the network on the 1568 test images: 88.5204081632653%\n",
      "Accuracy of the network on the 1584 test images: 88.51010101010101%\n",
      "Accuracy of the network on the 1600 test images: 88.5%\n",
      "Accuracy of the network on the 1616 test images: 88.5519801980198%\n",
      "Accuracy of the network on the 1632 test images: 88.6029411764706%\n",
      "Accuracy of the network on the 1648 test images: 88.65291262135922%\n",
      "Accuracy of the network on the 1664 test images: 88.64182692307692%\n",
      "Accuracy of the network on the 1680 test images: 88.69047619047619%\n",
      "Accuracy of the network on the 1696 test images: 88.73820754716981%\n",
      "Accuracy of the network on the 1712 test images: 88.78504672897196%\n",
      "Accuracy of the network on the 1728 test images: 88.77314814814815%\n",
      "Accuracy of the network on the 1744 test images: 88.87614678899082%\n",
      "Accuracy of the network on the 1760 test images: 88.92045454545455%\n",
      "Accuracy of the network on the 1776 test images: 88.90765765765765%\n",
      "Accuracy of the network on the 1792 test images: 89.00669642857143%\n",
      "Accuracy of the network on the 1808 test images: 89.10398230088495%\n",
      "Accuracy of the network on the 1824 test images: 88.98026315789474%\n",
      "Accuracy of the network on the 1840 test images: 88.80434782608695%\n",
      "Accuracy of the network on the 1856 test images: 88.90086206896552%\n",
      "Accuracy of the network on the 1872 test images: 88.9423076923077%\n",
      "Accuracy of the network on the 1888 test images: 88.87711864406779%\n",
      "Accuracy of the network on the 1904 test images: 88.91806722689076%\n",
      "Accuracy of the network on the 1920 test images: 88.85416666666667%\n",
      "Accuracy of the network on the 1936 test images: 88.94628099173553%\n",
      "Accuracy of the network on the 1952 test images: 88.98565573770492%\n",
      "Accuracy of the network on the 1968 test images: 88.92276422764228%\n",
      "Accuracy of the network on the 1984 test images: 88.9616935483871%\n",
      "Accuracy of the network on the 2000 test images: 89.0%\n",
      "Accuracy of the network on the 2016 test images: 88.98809523809524%\n",
      "Accuracy of the network on the 2032 test images: 89.0255905511811%\n",
      "Accuracy of the network on the 2048 test images: 89.111328125%\n",
      "Accuracy of the network on the 2064 test images: 89.09883720930233%\n",
      "Accuracy of the network on the 2080 test images: 89.08653846153847%\n",
      "Accuracy of the network on the 2096 test images: 89.12213740458016%\n",
      "Accuracy of the network on the 2112 test images: 89.15719696969697%\n",
      "Accuracy of the network on the 2128 test images: 89.14473684210526%\n",
      "Accuracy of the network on the 2144 test images: 88.99253731343283%\n",
      "Accuracy of the network on the 2160 test images: 89.02777777777777%\n",
      "Accuracy of the network on the 2176 test images: 89.10845588235294%\n",
      "Accuracy of the network on the 2192 test images: 88.73175182481752%\n",
      "Accuracy of the network on the 2208 test images: 88.76811594202898%\n",
      "Accuracy of the network on the 2224 test images: 88.71402877697842%\n",
      "Accuracy of the network on the 2240 test images: 88.75%\n",
      "Accuracy of the network on the 2256 test images: 88.7854609929078%\n",
      "Accuracy of the network on the 2272 test images: 88.77640845070422%\n",
      "Accuracy of the network on the 2288 test images: 88.81118881118881%\n",
      "Accuracy of the network on the 2304 test images: 88.75868055555556%\n",
      "Accuracy of the network on the 2320 test images: 88.79310344827586%\n",
      "Accuracy of the network on the 2336 test images: 88.6986301369863%\n",
      "Accuracy of the network on the 2352 test images: 88.69047619047619%\n",
      "Accuracy of the network on the 2368 test images: 88.64020270270271%\n",
      "Accuracy of the network on the 2384 test images: 88.63255033557047%\n",
      "Accuracy of the network on the 2400 test images: 88.70833333333333%\n",
      "Accuracy of the network on the 2416 test images: 88.70033112582782%\n",
      "Accuracy of the network on the 2432 test images: 88.65131578947368%\n",
      "Accuracy of the network on the 2448 test images: 88.64379084967321%\n",
      "Accuracy of the network on the 2464 test images: 88.63636363636364%\n",
      "Accuracy of the network on the 2480 test images: 88.66935483870968%\n",
      "Accuracy of the network on the 2496 test images: 88.62179487179488%\n",
      "Accuracy of the network on the 2512 test images: 88.57484076433121%\n",
      "Accuracy of the network on the 2528 test images: 88.56803797468355%\n",
      "Accuracy of the network on the 2544 test images: 88.6006289308176%\n",
      "Accuracy of the network on the 2560 test images: 88.5546875%\n",
      "Accuracy of the network on the 2576 test images: 88.54813664596273%\n",
      "Accuracy of the network on the 2592 test images: 88.58024691358025%\n",
      "Accuracy of the network on the 2608 test images: 88.57361963190183%\n",
      "Accuracy of the network on the 2624 test images: 88.60518292682927%\n",
      "Accuracy of the network on the 2640 test images: 88.59848484848484%\n",
      "Accuracy of the network on the 2656 test images: 88.59186746987952%\n",
      "Accuracy of the network on the 2672 test images: 88.54790419161677%\n",
      "Accuracy of the network on the 2688 test images: 88.54166666666667%\n",
      "Accuracy of the network on the 2704 test images: 88.46153846153847%\n",
      "Accuracy of the network on the 2720 test images: 88.34558823529412%\n",
      "Accuracy of the network on the 2728 test images: 88.26979472140762%\n",
      "Epoch [10/10], Loss: train_loss399.0000, Accuracy: 88.26979472140762%\n"
     ]
    }
   ],
   "source": [
    "# 测试模型\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to('cuda')\n",
    "        labels = labels.to('cuda')\n",
    "        \n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        # 计算测试集的accuracy并写入TensorBoard\n",
    "        accuracy = 100 * correct / total\n",
    "        test_logger.add_scalar('accuracy', accuracy, epoch)\n",
    "        # print(f'Accuracy of the network on the {total} test images: {100 * correct / total}%')\n",
    "        # # 输出每个epoch的信息\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: train_loss{len(train_loader):.4f}, Accuracy: {accuracy}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy.linalg.lapack_lite' has no attribute '_ilp64'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_30504/2659852740.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# 测试模型\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/3D/lib/python3.7/site-packages/sklearn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_distributor_init\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__check_build\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_show_versions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshow_versions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/3D/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_IS_32BIT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m from .utils._tags import (\n\u001b[1;32m     19\u001b[0m     \u001b[0m_DEFAULT_TAGS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/3D/lib/python3.7/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataConversionWarning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdeprecation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeprecated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfixes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnp_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_estimator_html_repr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mestimator_html_repr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m from .validation import (\n",
      "\u001b[0;32m~/anaconda3/envs/3D/lib/python3.7/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlsqr\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msparse_lsqr\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mthreadpoolctl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/3D/lib/python3.7/site-packages/scipy/stats/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    439\u001b[0m \"\"\"\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmorestats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/3D/lib/python3.7/site-packages/scipy/stats/stats.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mspecial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmstats_basic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m from ._stats_mstats_common import (_find_repeats, linregress, theilslopes,\n",
      "\u001b[0;32m~/anaconda3/envs/3D/lib/python3.7/site-packages/scipy/stats/distributions.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#       instead of `git blame -Lxxx,+x`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_distn_infrastructure\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrv_discrete\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrv_continuous\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrv_frozen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_continuous_distns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/3D/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# for root finding for continuous distribution ppf, and max likelihood\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# estimation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# for functions of continuous distributions (e.g. moments, entropy, cdf)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/3D/lib/python3.7/site-packages/scipy/optimize/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_minimize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_root\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_root_scalar\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/3D/lib/python3.7/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_trustregion_krylov\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_minimize_trust_krylov\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_trustregion_exact\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_minimize_trustregion_exact\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_trustregion_constr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_minimize_trustregion_constr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# constrained minimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/3D/lib/python3.7/site-packages/scipy/optimize/_trustregion_constr/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mminimize_trustregion_constr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_minimize_trustregion_constr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0m__all__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'_minimize_trustregion_constr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/3D/lib/python3.7/site-packages/scipy/optimize/_trustregion_constr/minimize_trustregion_constr.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinearOperator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_differentiable_functions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVectorFunction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m from .._constraints import (\n\u001b[0m\u001b[1;32m      6\u001b[0m     NonlinearConstraint, LinearConstraint, PreparedConstraint, strict_bounds)\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hessian_update_strategy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBFGS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/3D/lib/python3.7/site-packages/scipy/optimize/_constraints.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOptimizeWarning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwarnings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msuppress_warnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/3D/lib/python3.7/site-packages/numpy/testing/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0munittest\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTestCase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_private\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_private\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdecorators\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m from ._private.nosetester import (\n",
      "\u001b[0;32m~/anaconda3/envs/3D/lib/python3.7/site-packages/numpy/testing/_private/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0mIS_PYPY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplatform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_implementation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'PyPy'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0mHAS_REFCOUNT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'getrefcount'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0mHAS_LAPACK64\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlapack_lite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ilp64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy.linalg.lapack_lite' has no attribute '_ilp64'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix, roc_curve, auc\n",
    "\n",
    "# 测试模型\n",
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to('cuda')\n",
    "        labels = labels.to('cuda')\n",
    "        \n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        # 保存预测结果和真实标签，用于计算指标\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "\n",
    "    # 计算精确率、召回率和混淆矩阵\n",
    "    precision = precision_score(y_true, y_pred, average='macro')\n",
    "    recall = recall_score(y_true, y_pred, average='macro')\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # 计算ROC曲线和AUC\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # 将指标写入TensorBoard\n",
    "    test_logger.add_scalar('accuracy', accuracy, epoch)\n",
    "    test_logger.add_scalar('precision', precision, epoch)\n",
    "    test_logger.add_scalar('recall', recall, epoch)\n",
    "    test_logger.add_scalar('roc_auc', roc_auc, epoch)\n",
    "    # 可以使用 add_image() 方法将混淆矩阵转换为图像并写入TensorBoard\n",
    "    # 或者使用 add_figure() 方法将 ROC曲线绘制为图像并写入TensorBoard\n",
    "    # ...\n",
    "\n",
    "    # 输出每个epoch的信息\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: train_loss{len(train_loader):.4f}, Accuracy: {accuracy}%, Precision: {precision}, Recall: {recall}, ROC AUC: {roc_auc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "# 加载要预测的图像并进行预处理\n",
    "image_path = '/home/ubuntu/DeepLearning/U-net/Pytorch-UNet/headtest.jpg'\n",
    "image = Image.open(image_path).convert('L')  # 转换为灰度图像\n",
    "image = transform(image).unsqueeze(0)  # 转换为张量并添加一个维度\n",
    "\n",
    "# 将图像传递给模型进行预测\n",
    "with torch.no_grad():\n",
    "    output = model(image.to('cuda'))\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "\n",
    "# 输出预测结果\n",
    "print('Predicted label:', predicted.item())\n",
    "for i, class_name in enumerate(train_dataset.classes):\n",
    "    print(f\"Class index {i}: {class_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3D",
   "language": "python",
   "name": "3d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
